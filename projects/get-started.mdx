---
title: Get Started with Projects
description: Create your first AI development project and learn the complete workflow from dataset creation to model evaluation.
---

# Creating Your First Project

Projects provide a guided, end-to-end workflow for AI model development. This guide walks you through creating a complete project from start to finish.

<img src="https://static.premai.io/prem-saas-docs/projects/project-setup-flow.png" alt="Project Setup Flow" />

## Step 1: General Setup

<Steps>
  <Step title="Navigate to Projects">
    From the main dashboard, click **Projects** in the left sidebar, then click **+ Create Project**.

    <img src="https://static.premai.io/prem-saas-docs/projects/navigate-to-projects.gif" alt="GIF showing navigation to Projects section" />
  </Step>

  <Step title="Configure Project Basics">
    **Project Name**: Choose a descriptive name that reflects your use case

    **Description** (Optional): Add context about your project goals

    **Base Model**: Select the foundation model you want to fine-tune

    <img src="https://static.premai.io/prem-saas-docs/projects/general-setup.png" alt="Project general setup configuration" />

    <Tip>
      Choose your base model carefully - it significantly impacts training time, cost, and final performance.
    </Tip>
  </Step>
</Steps>

## Step 2: Dataset Creation

You have **two paths** for dataset creation. Choose the one that fits your situation:

### Path A: Upload Existing JSONL Dataset

<Steps>
  <Step title="Select Upload Option">
    In the **Create Dataset** section, choose **Upload Existing Dataset**.

    <img src="https://static.premai.io/prem-saas-docs/projects/dataset-upload-option.png" alt="Dataset upload option selection" />
  </Step>

  <Step title="Upload Your JSONL File">
    - **Dataset Name**: Enter a descriptive name
    - **Upload File**: Select your properly formatted JSONL file
    - **Validation**: The system will automatically validate your dataset format

    <img src="https://static.premai.io/prem-saas-docs/projects/upload-jsonl-dataset.gif" alt="JSONL dataset upload process" />

    <Note>
      Need help with JSONL format? See our [Datasets Overview](/datasets/overview) for detailed formatting requirements.
    </Note>
  </Step>
</Steps>

### Path B: Generate Synthetic Dataset

<Steps>
  <Step title="Select Synthetic Generation">
    In the **Create Dataset** section, choose **Generate Synthetic Dataset**.

    <img src="https://static.premai.io/prem-saas-docs/projects/synthetic-option.png" alt="Synthetic dataset generation option" />
  </Step>

  <Step title="Choose Data Sources">
    Select your input sources:
    - **Files**: PDF, DOCX, TXT, HTML, PPTX
    - **YouTube Videos**: Individual videos or playlists
    - **Web URLs**: Website content extraction
    - **Mixed Sources**: Combine multiple input types

    **QA Pairs per Source**: Set how many question-answer pairs to generate from each input

    <img src="https://static.premai.io/prem-saas-docs/projects/synthetic-sources.gif" alt="Selecting synthetic data sources" />
  </Step>

  <Step title="Configure Advanced Settings (Optional)">
    **Rules & Constraints**: Define generation requirements
    ```text
    - Focus on technical accuracy
    - Use domain-specific terminology
    - Maintain consistent formatting
    - Generate questions of varying complexity
    ```

    **Question Format**: Guide question structure
    ```text
    Generate questions that test understanding of [TOPIC] using the context provided.
    Focus on practical applications and real-world scenarios.
    ```

    **Answer Format**: Define expected answer style
    ```text
    Provide detailed, step-by-step answers with examples where applicable.
    Include code snippets or specific instructions when relevant.
    ```

    **Creativity Level**: Adjust generation diversity (0-100)

    <img src="https://static.premai.io/prem-saas-docs/projects/synthetic-advanced.png" alt="Advanced synthetic generation settings" />

    <Tip>
      For structured outputs (like JSON extraction), set creativity to 0. For conversational models, use 30-50.
    </Tip>
  </Step>

  <Step title="Review and Generate">
    Review your configuration summary:
    - Data sources and expected output count
    - Generation settings and estimated cost
    - Processing time estimate

    Click **Generate Dataset** to start the process.

    <img src="https://static.premai.io/prem-saas-docs/projects/synthetic-review.png" alt="Synthetic generation review and confirmation" />
  </Step>
</Steps>

## Step 3: Dataset Creation Progress

Monitor your dataset creation in real-time:

<img src="https://static.premai.io/prem-saas-docs/projects/dataset-progress.gif" alt="Dataset creation progress monitoring" />

- **Processing Status**: See which files are being processed
- **Generation Progress**: Track QA pair creation
- **Estimated Completion**: Time remaining for generation
- **Cost Tracking**: Monitor usage costs

<Note>
  Dataset generation typically takes 2-5 minutes per input source, depending on size and complexity.
</Note>

## Step 4: Review and Refine Dataset

Once generation completes, review your dataset:

<Steps>
  <Step title="Preview Generated Data">
    Browse through the generated QA pairs to ensure quality and relevance.

    <img src="https://static.premai.io/prem-saas-docs/projects/dataset-preview.png" alt="Dataset preview and review interface" />
  </Step>

  <Step title="Edit or Remove Entries (Optional)">
    - **Edit**: Modify questions or answers for better accuracy
    - **Delete**: Remove low-quality or irrelevant pairs
    - **Add**: Manually add additional QA pairs if needed

    <img src="https://static.premai.io/prem-saas-docs/projects/dataset-editing.gif" alt="Editing dataset entries" />
  </Step>

  <Step title="Create Dataset Snapshot">
    Click **Create Snapshot** to save the final version for fine-tuning.

    <img src="https://static.premai.io/prem-saas-docs/projects/create-snapshot.png" alt="Creating dataset snapshot" />

    <Warning>
      Always create a snapshot before proceeding to fine-tuning. This preserves your dataset state and enables reproducibility.
    </Warning>
  </Step>
</Steps>

## Step 5: Fine-tune Your Model

With your dataset ready, proceed to model fine-tuning:

<Steps>
  <Step title="Configure Fine-tuning Parameters">
    **Training Configuration**:
    - **Learning Rate**: Start with recommended defaults
    - **Batch Size**: Adjust based on dataset size
    - **Epochs**: Number of training iterations
    - **Validation Split**: Percentage for validation (typically 10-20%)

    <img src="https://static.premai.io/prem-saas-docs/projects/finetuning-config.png" alt="Fine-tuning configuration settings" />
  </Step>

  <Step title="Start Fine-tuning Job">
    Review your configuration and start the training process.

    **Estimated Duration**: Based on dataset size and model complexity
    **Cost Estimate**: Training costs and resource usage

    <img src="https://static.premai.io/prem-saas-docs/projects/start-finetuning.gif" alt="Starting the fine-tuning process" />
  </Step>

  <Step title="Monitor Training Progress">
    Track your model's training in real-time:
    - **Loss Curves**: Training and validation loss over time
    - **Performance Metrics**: Accuracy and other relevant metrics
    - **Resource Usage**: GPU utilization and memory consumption

    <img src="https://static.premai.io/prem-saas-docs/projects/training-progress.png" alt="Fine-tuning progress monitoring" />
  </Step>
</Steps>

<Note>
  Fine-tuning duration varies from 30 minutes to several hours depending on dataset size, model complexity, and chosen parameters. For detailed guidance, see our [Fine-tuning Guide](/finetuning/get-started).
</Note>

## Step 6: Define Metrics

Before evaluating your model, define the metrics that will measure success for your specific use case:

<Steps>
  <Step title="Generate Rules">
    Create evaluation rules that define what constitutes good vs. poor responses for your use case.

    **Examples**:
    - Technical accuracy for code generation
    - Tone appropriateness for customer support
    - Factual correctness for Q&A systems

    <img src="https://static.premai.io/prem-saas-docs/projects/generate-rules.png" alt="Generating evaluation rules" />
  </Step>

  <Step title="Create Custom Metrics">
    Define specific metrics that align with your business objectives:

    **Common Metric Types**:
    - **Accuracy**: Percentage of correct responses
    - **Relevance**: How well answers address the question
    - **Consistency**: Similar inputs produce similar outputs
    - **Safety**: No harmful or inappropriate content

    <img src="https://static.premai.io/prem-saas-docs/projects/create-metrics.png" alt="Creating custom metrics" />

    <Tip>
      Start with 2-3 key metrics that directly impact your use case. You can always add more later.
    </Tip>
  </Step>
</Steps>

<Note>
  Well-defined metrics are crucial for meaningful evaluation. Take time to think about what "success" looks like for your specific use case. Learn more in our [Evaluation Metrics Guide](/evaluations/metrics).
</Note>

## Step 7: Evaluate Your Model

With your metrics defined, evaluate your model's performance:

<Steps>
  <Step title="Choose Evaluation Metrics">
    Select metrics relevant to your use case:
    - **Accuracy**: Overall correctness
    - **Relevance**: Answer appropriateness
    - **Consistency**: Response reliability
    - **Custom Metrics**: Domain-specific evaluation criteria

    <img src="https://static.premai.io/prem-saas-docs/projects/evaluation-metrics.png" alt="Selecting evaluation metrics" />
  </Step>

  <Step title="Run Evaluation">
    Start the evaluation process against your test dataset.

    <img src="https://static.premai.io/prem-saas-docs/projects/run-evaluation.gif" alt="Running model evaluation" />
  </Step>

  <Step title="Review Results">
    Analyze your model's performance:
    - **Overall Scores**: Aggregate performance metrics
    - **Per-Question Analysis**: Detailed breakdown of responses
    - **Comparison**: Performance vs. base model
    - **Recommendations**: Suggested improvements

    <img src="https://static.premai.io/prem-saas-docs/projects/evaluation-results.png" alt="Model evaluation results dashboard" />
  </Step>
</Steps>

<Note>
  Evaluation typically takes 5-15 minutes depending on test dataset size. Learn more about evaluation strategies in our [Evaluations Guide](/evaluations/get-started).
</Note>

## Step 8: Project Complete

Congratulations! Your project is now complete. You have:

✅ **Created or uploaded a quality dataset**
✅ **Successfully fine-tuned your model**
✅ **Defined custom metrics for your use case**
✅ **Validated performance through evaluation**
✅ **Generated a production-ready AI model**

### Next Steps

<CardGroup cols={2}>
  <Card title="Deploy Your Model" icon="rocket" href="/inference/self-host">
    Learn how to deploy your fine-tuned model for production use.
  </Card>
  <Card title="API Integration" icon="code" href="/api-reference/introduction">
    Integrate your model into applications using our API.
  </Card>
</CardGroup>

<CardGroup cols={2}>
  <Card title="Model Experiments" icon="flask" href="/finetuning/experiments">
    Run experiments to further optimize your model.
  </Card>
  <Card title="Create Another Project" icon="plus" href="/projects/get-started">
    Apply what you've learned to new use cases.
  </Card>
</CardGroup>

---

## Troubleshooting Common Issues

<AccordionGroup>
  <Accordion title="Dataset Generation Failed">
    **Possible causes:**
    - Invalid input file formats
    - Files too large or corrupted
    - Network issues with URL sources

    **Solutions:**
    - Verify file formats are supported
    - Check file size limits (max 50MB per file)
    - Test URLs manually to ensure accessibility
  </Accordion>

  <Accordion title="Fine-tuning Taking Too Long">
    **Possible causes:**
    - Large dataset size
    - Complex model architecture
    - High epoch count

    **Solutions:**
    - Consider reducing dataset size for initial testing
    - Lower epoch count for faster iteration
    - Use smaller base models for experimentation
  </Accordion>

  <Accordion title="Poor Evaluation Results">
    **Possible causes:**
    - Insufficient training data
    - Low-quality synthetic data
    - Inappropriate base model selection

    **Solutions:**
    - Review and clean your dataset
    - Add more diverse training examples
    - Try a different base model better suited for your task
  </Accordion>
</AccordionGroup>

## Need Help?

<CardGroup cols={2}>
  <Card title="Best Practices" icon="lightbulb" href="/projects/best-practices">
    Learn optimization tips and proven workflows.
  </Card>
  <Card title="Community Support" icon="discord" href="https://discord.gg/tWwg9RSCXJ">
    Get help from the Prem community.
  </Card>
</CardGroup>
