---
title: "YouTube Synthetic Dataset Workflow"
description: "Generate synthetic Q&A pairs from YouTube videos, create snapshots, and launch fine-tuning."
---

<Note>
  Export your Prem API key as `API_KEY` before running any script. Set `API_BASE_URL` (defaults to `https://localhost`).
  Customize `USER_INSTRUCTIONS` based on your video's subject matter for better results.
</Note>


<Steps>
  <Step>
  # Create project and generate synthetic dataset

  <CodeGroup>
  ```ts TypeScript
  const { project_id } = await api('/api/v1/public/projects/create', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ name: 'YouTube AI Project', goal: 'Train from video content' })
  });

  const formData = new FormData();
  formData.append('project_id', project_id);
  formData.append('name', 'YouTube Dataset');
  formData.append('youtube_urls[0]', YOUTUBE_URL);
  formData.append('pairs_to_generate', '50');
  formData.append('pair_type', 'qa');
  formData.append('user_instructions', USER_INSTRUCTIONS);

  const { dataset_id } = await api('/api/v1/public/datasets/create-synthetic', {
    method: 'POST',
    body: formData
  });
  ```
  ```python Python
  response = requests.post(
      f"{API_BASE_URL}/api/v1/public/projects/create",
      headers={"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"},
      json={"name": "YouTube AI Project", "goal": "Train from video content"}
  )
  response.raise_for_status()
  project_id = response.json()["project_id"]

  form_data = {
      "project_id": project_id,
      "name": "YouTube Dataset",
      "youtube_urls[0]": YOUTUBE_URL,
      "pairs_to_generate": "50",
      "pair_type": "qa",
      "user_instructions": USER_INSTRUCTIONS
  }
  response = requests.post(
      f"{API_BASE_URL}/api/v1/public/datasets/create-synthetic",
      headers={"Authorization": f"Bearer {API_KEY}"},
      data=form_data
  )
  response.raise_for_status()
  dataset_id = response.json()["dataset_id"]
  ```
  </CodeGroup>

  Create a project, then submit YouTube URLs to generate synthetic Q&A pairs. The generation can take 5-10 minutes.
  </Step>

  <Step>
  # Wait for dataset generation

  <CodeGroup>
  ```ts TypeScript
  let dataset;
  let checks = 0;
  do {
    await sleep(5000);
    dataset = await api(`/api/v1/public/datasets/${dataset_id}`);
    if (checks++ % 6 === 0) {
      console.log(`Status: ${dataset.status}, ${dataset.datapoints_count} datapoints`);
    }
  } while (dataset.status === 'processing');
  ```
  ```python Python
  checks = 0
  while True:
      time.sleep(5)
      response = requests.get(
          f"{API_BASE_URL}/api/v1/public/datasets/{dataset_id}",
          headers={"Authorization": f"Bearer {API_KEY}"}
      )
      response.raise_for_status()
      dataset = response.json()
      if checks % 6 == 0:
          print(f"Status: {dataset['status']}, {dataset['datapoints_count']} datapoints")
      checks += 1
      if dataset["status"] != "processing":
          break
  ```
  </CodeGroup>

  Poll the dataset status every 5 seconds. Log progress every 30 seconds to avoid spam.
  </Step>

  <Step>
  # Create snapshot and get recommendations

  <CodeGroup>
  ```ts TypeScript
  const { snapshot_id } = await api('/api/v1/public/snapshots/create', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ dataset_id, split_percentage: 80 })
  });

  await api('/api/v1/public/recommendations/generate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ snapshot_id, reasoning: false })
  });

  let recs;
  do {
    await sleep(5000);
    recs = await api(`/api/v1/public/recommendations/${snapshot_id}?reasoning=false`);
  } while (recs.status === 'processing');
  ```
  ```python Python
  response = requests.post(
      f"{API_BASE_URL}/api/v1/public/snapshots/create",
      headers={"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"},
      json={"dataset_id": dataset_id, "split_percentage": 80}
  )
  response.raise_for_status()
  snapshot_id = response.json()["snapshot_id"]

  response = requests.post(
      f"{API_BASE_URL}/api/v1/public/recommendations/generate",
      headers={"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"},
      json={"snapshot_id": snapshot_id, "reasoning": False}
  )
  response.raise_for_status()

  while True:
      time.sleep(5)
      response = requests.get(
          f"{API_BASE_URL}/api/v1/public/recommendations/{snapshot_id}",
          headers={"Authorization": f"Bearer {API_KEY}"},
          params={"reasoning": "false"}
      )
      response.raise_for_status()
      recs = response.json()
      if recs["status"] != "processing":
          break
  ```
  </CodeGroup>

  Create a snapshot with 80/20 train/validation split, then request model recommendations.
  </Step>

  <Step>
  # Launch fine-tuning job

  <CodeGroup>
  ```ts TypeScript
  const experiments = recs.recommended_models
    .filter((m: any) => m.recommended)
    .map((m: any) => ({
      base_model_id: m.baseModelId,
      batch_size: m.lora_hyperparameters.batchSize,
      learning_rate_multiplier: m.lora_hyperparameters.learningRateMultiplier,
      n_epochs: m.lora_hyperparameters.nEpochs,
      lora: true
    }));

  const { job_id } = await api('/api/v1/public/finetuning/create', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ snapshot_id, name: 'YouTube Model', reasoning: false, experiments })
  });
  ```
  ```python Python
  experiments = [
      {
          "base_model_id": m["base_model_id"],
          "batch_size": m["lora_hyperparameters"]["batch_size"],
          "learning_rate_multiplier": m["lora_hyperparameters"]["learning_rate_multiplier"],
          "n_epochs": m["lora_hyperparameters"]["n_epochs"],
          "lora": True
      }
      for m in recs["recommended_models"] if m["recommended"]
  ]

  response = requests.post(
      f"{API_BASE_URL}/api/v1/public/finetuning/create",
      headers={"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"},
      json={"snapshot_id": snapshot_id, "name": "YouTube Model", "reasoning": False, "experiments": experiments}
  )
  response.raise_for_status()
  job_id = response.json()["job_id"]
  ```
  </CodeGroup>

  Filter recommended models and create a fine-tuning job using LoRA hyperparameters.
  </Step>

  <Step>
  # Monitor job progress

  <CodeGroup>
  ```ts TypeScript
  for (let i = 0; i < 30; i++) {
    await sleep(10000);
    const job = await api(`/api/v1/public/finetuning/${job_id}`);
    console.log(`Status: ${job.status}`);
    job.experiments.forEach((e: any) => {
      console.log(`  - Exp #${e.experiment_number}: ${e.status} ${e.model_id || ''}`);
    });
    if (job.status !== 'processing') break;
  }
  ```
  ```python Python
  for i in range(30):
      time.sleep(10)
      response = requests.get(
          f"{API_BASE_URL}/api/v1/public/finetuning/{job_id}",
          headers={"Authorization": f"Bearer {API_KEY}"}
      )
      response.raise_for_status()
      job = response.json()
      print(f"Status: {job['status']}")
      for exp in job["experiments"]:
          print(f"  - Exp #{exp['experiment_number']}: {exp['status']} {exp.get('model_id', '')}")
      if job["status"] != "processing":
          break
  ```
  </CodeGroup>

  Poll job status every 10 seconds. Each experiment shows its progress and final model ID.
  </Step>
</Steps>

## Full Example

<CodeGroup>
```ts TypeScript
#!/usr/bin/env bun

/**
 * Example 2: YouTube synthetic dataset workflow
 * 1. Create project → 2. Generate synthetic data from YouTube → 3. Create snapshot → 4. Get recommendations → 5. Run finetuning
 */

const API_BASE_URL = process.env.API_BASE_URL || 'https://localhost';
const API_KEY = process.env.API_KEY;
const YOUTUBE_URL = 'https://www.youtube.com/watch?v=51y4KatMBFI';

const USER_INSTRUCTIONS =
	'Generate detailed question-answer pairs about the key concepts, main topics, important details, and technical information presented in the video. Focus on extracting specific facts, explanations, definitions, examples, and insights that are directly mentioned or demonstrated. Create questions that test understanding of the core subject matter and provide comprehensive answers based on the video content.';

// Disable TLS verification for local development with self-signed certs
process.env.NODE_TLS_REJECT_UNAUTHORIZED = '0';

if (!API_KEY) {
	console.error('Error: API_KEY environment variable is required');
	console.error('Please create a .env file based on .env.example');
	process.exit(1);
}

async function api(endpoint: string, options: any = {}): Promise<any> {
	const res = await fetch(`${API_BASE_URL}${endpoint}`, {
		...options,
		headers: { Authorization: `Bearer ${API_KEY}`, ...options.headers },
	});
	if (!res.ok) {
		const err: any = await res.json().catch(() => ({}));
		const errorMsg = typeof err.error === 'string' ? err.error : JSON.stringify(err);
		throw new Error(`${res.status}: ${errorMsg}`);
	}
	return res.json();
}

function sleep(ms: number) {
	return new Promise((r) => setTimeout(r, ms));
}

async function main() {
	console.log('\n=== YouTube Synthetic Workflow ===\n');

	// 1. Create project
	console.log('1. Creating project...');
	const { project_id } = await api('/api/v1/public/projects/create', {
		method: 'POST',
		headers: { 'Content-Type': 'application/json' },
		body: JSON.stringify({ name: 'YouTube AI Project', goal: 'Train from video content' }),
	});
	console.log(`   ✓ Project: ${project_id}\n`);

	// 2. Generate synthetic dataset
	console.log('2. Generating synthetic dataset from YouTube...');
	console.log(`   URL: ${YOUTUBE_URL}`);
	const formData = new FormData();
	formData.append('project_id', project_id);
	formData.append('name', 'YouTube Dataset');
	formData.append('youtube_urls[0]', YOUTUBE_URL);
	formData.append('pairs_to_generate', '50');
	formData.append('pair_type', 'qa');
	formData.append('user_instructions', USER_INSTRUCTIONS);

	const { dataset_id } = await api('/api/v1/public/datasets/create-synthetic', {
		method: 'POST',
		body: formData,
	});
	console.log(`   ✓ Dataset: ${dataset_id}`);

	// Wait for dataset (can take several minutes)
	console.log('   Waiting for generation (may take 5-10 minutes)...');
	let dataset;
	let checks = 0;
	do {
		await sleep(5000);
		dataset = await api(`/api/v1/public/datasets/${dataset_id}`);
		if (checks++ % 6 === 0) {
			console.log(`   Status: ${dataset.status}, ${dataset.datapoints_count} datapoints`);
		}
	} while (dataset.status === 'processing');
	console.log(`   ✓ Ready: ${dataset.datapoints_count} datapoints\n`);

	// 3. Create snapshot
	console.log('3. Creating snapshot...');
	const { snapshot_id } = await api('/api/v1/public/snapshots/create', {
		method: 'POST',
		headers: { 'Content-Type': 'application/json' },
		body: JSON.stringify({ dataset_id, split_percentage: 80 }),
	});
	console.log(`   ✓ Snapshot: ${snapshot_id}\n`);

	// 4. Generate recommendations
	console.log('4. Generating recommendations...');
	await api('/api/v1/public/recommendations/generate', {
		method: 'POST',
		headers: { 'Content-Type': 'application/json' },
		body: JSON.stringify({ snapshot_id, reasoning: false }),
	});

	let recs;
	do {
		await sleep(5000);
		recs = await api(`/api/v1/public/recommendations/${snapshot_id}?reasoning=false`);
	} while (recs.status === 'processing');

	console.log(`   ✓ Recommended models:`);
	const recommendedCount = recs.recommended_models.filter((m: any) => m.recommended).length;
	console.log(`   Total models: ${recs.recommended_models.length}, Recommended: ${recommendedCount}`);
	recs.recommended_models.forEach((m: any) => {
		if (m.recommended) console.log(`     - ${m.baseModelId}`);
	});
	console.log();

	// 5. Create finetuning job
	console.log('5. Creating finetuning job...');
	const experiments = recs.recommended_models
		.filter((m: any) => m.recommended)
		.map((m: any) => ({
			base_model_id: m.baseModelId,
			batch_size: m.lora_hyperparameters.batchSize,
			learning_rate_multiplier: m.lora_hyperparameters.learningRateMultiplier,
			n_epochs: m.lora_hyperparameters.nEpochs,
			lora: true,
		}));

	if (experiments.length === 0) {
		console.error('\n✗ Error: No recommended models found. Cannot create finetuning job.');
		process.exit(1);
	}

	const { job_id } = await api('/api/v1/public/finetuning/create', {
		method: 'POST',
		headers: { 'Content-Type': 'application/json' },
		body: JSON.stringify({ snapshot_id, name: 'YouTube Model', reasoning: false, experiments }),
	});
	console.log(`   ✓ Job: ${job_id}\n`);

	// 6. Monitor (5 minutes max)
	console.log('6. Monitoring job...');
	for (let i = 0; i < 30; i++) {
		await sleep(10000);
		const job = await api(`/api/v1/public/finetuning/${job_id}`);
		console.log(`   Status: ${job.status}`);
		job.experiments.forEach((e: any) => {
			console.log(`     - Exp #${e.experiment_number}: ${e.status} ${e.model_id || ''}`);
		});
		if (job.status !== 'processing') break;
	}

	console.log('\n✓ Done!\n');
}

main().catch((err) => {
	console.error('\n✗ Error:', err.message);
	process.exit(1);
});
```
```python Python
#!/usr/bin/env python3

"""
Example 2: YouTube synthetic dataset workflow
1. Create project → 2. Generate synthetic data from YouTube → 3. Create snapshot → 4. Get recommendations → 5. Run finetuning
"""

import os
import time
import requests

API_BASE_URL = os.getenv("API_BASE_URL", "https://localhost")
API_KEY = os.getenv("API_KEY")
YOUTUBE_URL = "https://www.youtube.com/watch?v=51y4KatMBFI"

USER_INSTRUCTIONS = (
    "Generate detailed question-answer pairs about the key concepts, main topics, important details, "
    "and technical information presented in the video. Focus on extracting specific facts, explanations, "
    "definitions, examples, and insights that are directly mentioned or demonstrated. Create questions "
    "that test understanding of the core subject matter and provide comprehensive answers based on the video content."
)

if not API_KEY:
    print("Error: API_KEY environment variable is required")
    exit(1)


def api(endpoint: str, method: str = "GET", **kwargs):
    response = requests.request(
        method=method,
        url=f"{API_BASE_URL}{endpoint}",
        headers={"Authorization": f"Bearer {API_KEY}", **kwargs.pop("headers", {})},
        **kwargs
    )
    if not response.ok:
        err = response.json() if response.content else {}
        error_msg = err.get("error", str(err)) if isinstance(err, dict) else str(err)
        raise Exception(f"{response.status_code}: {error_msg}")
    return response.json()


def main():
    print("\n=== YouTube Synthetic Workflow ===\n")

    # Create project
    print("1. Creating project...")
    result = api("/api/v1/public/projects/create", method="POST", headers={"Content-Type": "application/json"}, json={"name": "YouTube AI Project", "goal": "Train from video content"})
    project_id = result["project_id"]
    print(f"   ✓ Project: {project_id}\n")

    # Generate synthetic dataset
    print("2. Generating synthetic dataset from YouTube...")
    print(f"   URL: {YOUTUBE_URL}")
    form_data = {
        "project_id": project_id,
        "name": "YouTube Dataset",
        "youtube_urls[0]": YOUTUBE_URL,
        "pairs_to_generate": "50",
        "pair_type": "qa",
        "user_instructions": USER_INSTRUCTIONS
    }
    result = api("/api/v1/public/datasets/create-synthetic", method="POST", data=form_data)
    dataset_id = result["dataset_id"]
    print(f"   ✓ Dataset: {dataset_id}")

    # Wait for dataset (can take several minutes)
    print("   Waiting for generation (may take 5-10 minutes)...")
    checks = 0
    while True:
        time.sleep(5)
        dataset = api(f"/api/v1/public/datasets/{dataset_id}")
        if checks % 6 == 0:
            print(f"   Status: {dataset['status']}, {dataset['datapoints_count']} datapoints")
        checks += 1
        if dataset["status"] != "processing":
            break
    print(f"   ✓ Ready: {dataset['datapoints_count']} datapoints\n")

    # Create snapshot
    print("3. Creating snapshot...")
    result = api("/api/v1/public/snapshots/create", method="POST", headers={"Content-Type": "application/json"}, json={"dataset_id": dataset_id, "split_percentage": 80})
    snapshot_id = result["snapshot_id"]
    print(f"   ✓ Snapshot: {snapshot_id}\n")

    # Generate recommendations
    print("4. Generating recommendations...")
    api("/api/v1/public/recommendations/generate", method="POST", headers={"Content-Type": "application/json"}, json={"snapshot_id": snapshot_id, "reasoning": False})

    while True:
        time.sleep(5)
        recs = api(f"/api/v1/public/recommendations/{snapshot_id}", params={"reasoning": "false"})
        if recs["status"] != "processing":
            break

    print("   ✓ Recommended models:")
    recommended_count = sum(1 for m in recs["recommended_models"] if m["recommended"])
    print(f"   Total models: {len(recs['recommended_models'])}, Recommended: {recommended_count}")
    for m in recs["recommended_models"]:
        if m["recommended"]:
            print(f"     - {m['base_model_id']}")
    print()

    # Create finetuning job
    print("5. Creating finetuning job...")
    experiments = [
        {
            "base_model_id": m["base_model_id"],
            "batch_size": m["lora_hyperparameters"]["batch_size"],
            "learning_rate_multiplier": m["lora_hyperparameters"]["learning_rate_multiplier"],
            "n_epochs": m["lora_hyperparameters"]["n_epochs"],
            "lora": True
        }
        for m in recs["recommended_models"] if m["recommended"]
    ]

    if not experiments:
        print("\n✗ Error: No recommended models found. Cannot create finetuning job.")
        exit(1)

    result = api("/api/v1/public/finetuning/create", method="POST", headers={"Content-Type": "application/json"}, json={"snapshot_id": snapshot_id, "name": "YouTube Model", "reasoning": False, "experiments": experiments})
    job_id = result["job_id"]
    print(f"   ✓ Job: {job_id}\n")

    # Monitor (5 minutes max)
    print("6. Monitoring job...")
    for i in range(30):
        time.sleep(10)
        job = api(f"/api/v1/public/finetuning/{job_id}")
        print(f"   Status: {job['status']}")
        for exp in job["experiments"]:
            print(f"     - Exp #{exp['experiment_number']}: {exp['status']} {exp.get('model_id', '')}")
        if job["status"] != "processing":
            break

    print("\n✓ Done!\n")


if __name__ == "__main__":
    try:
        main()
    except Exception as err:
        print(f"\n✗ Error: {err}")
        exit(1)
```
</CodeGroup>
