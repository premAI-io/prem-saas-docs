---
icon: plug
title: Prem SDK
---

## Installation

You can install the Prem **Python** or **JavaScript SDKs** directly from [PyPI](https://pypi.org/project/premai/) or [npm](https://www.npmjs.com/package/@premai/prem-sdk).


<CodeGroup>

```bash Python
pip install premai
```

```bash JavaScript
npm install @premai/prem-sdk
```
</CodeGroup>

## Usage

### Getting Started

To use the **Prem** SDK, you need to obtain an API key. You can then create a `Prem` instance to make requests to the API.

<CodeGroup>
```python Python
from premai import Prem

client = Prem(
    api_key=YOUR_API_KEY
)
```
```javascript JavaScript
import Prem from '@premai/prem-sdk';

const client = new Prem({
  apiKey: "YOUR_API_KEY"
})

const project_id = PROJECT_ID
```
</CodeGroup>



## Chat completion

The `chat.completions` module is set to use default launchpad parameters unless otherwise specified. Optional parameters can also be defined as needed.

#### Here's an example:
<CodeGroup>
```python Python
messages = [
    {"role": "user", "content": "Who won the world series in 2020?"},
]
project_id = PROJECT_ID

# Create completion
response = client.chat.completions.create(
    project_id=project_id,
    messages=messages,
)

print(response.choices)
```
```javascript JavaScript
const messages = [
    { role: "user", content: "Who won the world series in 2020?" },
]

// Create completion
const responseSync = await client.chat.completions.create({
  project_id,
  messages
})

console.log(responseSync)
```
  
</CodeGroup>


### Chat completion with stream

You can also create a completion with a stream to receive the response in chunks by passing the `stream` parameter as `true` (default is `false`).

<CodeGroup>
```python Python
# Create completion with stream
response = client.chat.completions.create(
    project_id=project_id,
    messages=messages,
    stream=True,
)

for chunk in response:
    if chunk.choices[0].delta["content"]:
        print(chunk.choices[0].delta["content"], end="")
```
```javascript JavaScript
// Create completion with stream
const responseAsync = await client.chat.completions.create({
  project_id,
  messages,
  stream: true
})

for await (const chunk of responseAsync) {
  if (chunk.choices[0].delta.content) {
    process.stdout.write(chunk.choices[0].delta.content)
  }
}

console.log("\nTrace ID", responseAsync.trace_id)
```  
</CodeGroup>


### Optional parameters

By default, the `chat.completions` module uses the default launchpad parameters. You can also specify the following optional parameters:

- `session_id`: A unique identifier to maintain session context, useful for tracking conversations or data across multiple requests.
- `repositories`: Options for Retrieval Augmented Generation (RAG). Will override launched model settings. (More about that on next section)
- `model`: The model to use for completion. If omitted, the default launchpad model will be used.
- `system_prompt`: The system prompt to use for completion. If omitted, the default launchpad system prompt will be used.
- `max_tokens`: The maximum number of tokens to generate for completion. If omitted, the default launchpad max tokens will be used.
- `stream`: If set, partial message deltas will be sent, like in ChatGPT.
- `temperature`: The temperature to use for completion. If omitted, the default launchpad temperature will be used.

Example:

<CodeGroup>
```python Python
model = "gpt-3.5-turbo"
system_prompt = "You are a helpful assistant."
session_id = "my-session"
temperature = 0.7
messages = [
    { "role": "user", "content": "Who won the world series in 2020?" },
]

response = client.chat.completions.create(
    project_id=project_id,
    messages=messages,
    model=model,
    system_prompt=system_prompt,
    session_id=session_id,
    temperature=temperature
)

print(response)
```
```javascript JavaScript
const model = "gpt-3.5-turbo"
const system_prompt = "You are a helpful assistant."
const session_id = "my-session"
const temperature = 0.7
const messages = [
    { role: "user", content: "Who won the world series in 2020?" },
]

// Create completion
const response = await client.chat.completions.create({
  project_id,
  messages,
  model,
  system_prompt,
  session_id,
  temperature
})

console.log(response)
```
</CodeGroup>




## Enhanced Chat Completion with Retrieval Augmented Generation (RAG)

Enhance your chat completions by leveraging contextual data from specified `repositories`. A `repository` is a collection of `documents`, each containing information that can be utilized by the RAG system to provide enriched and context-aware responses.

**If you've linked your repositories in the launchpad, relaxâ€”you're all set for effortless chat completions!** The system automatically uses those parameters by default, ensuring a seamless and easy experience. However, if you wish to customize the process, you can specify the `repositories` parameter to fit your exact needs. Just define:

-   `ids`: Your selected repository IDs.
-   `similarity_threshold`: The least similarity score for content relevance.
-   `limit`: The number of content pieces to include.

For guidance on managing repositories, see the [Repositories](#repositories) section.

<CodeGroup>
```python Python
messages = [
    { "role": "user", "content": "Which is Jack's pet name?" },
]

repositories = dict(
  ids=[REPOSITORY_ID, ...],
  similarity_threshold=0.65,
  limit=3
)

# Create completion
response = client.chat.completions.create(
  project_id=PROJECT_ID,
  messages=messages,
  repositories=repositories,
  stream=False
)

print(response.choices[0].message.content)
# "Jack's pet name is Sparky."

print(response.document_chunks)
# E.g., [DocumentChunks(repository_id=4, document_id=14, chunk_id=15, document_name="pets_and_their_owners.txt", similarity_score=0.67, content="..."), ...]
```
```javascript JavaScript
const messages = [
    { role: "user", content: "Which is Jack's pet name?" },
]

const repositories = {
  ids: [REPOSITORY_ID, ...],
  similarity_threshold: 0.65,
  limit: 3
}

// Create completion
const response = await client.chat.completions.create({
  project_id,
  messages,
  repositories,
  stream: false
})

console.log(response.choices[0].message.content)
// "Jack's pet name is Sparky."

console.log(response.document_chunks)
// E.g. [{ repository_id=4, document_id=14, chunk_id=15, document_name="pets_and_their_owners.txt", similarity_score=0.67, content="..." }, ...]
```
</CodeGroup>


## Repositories
Repositories act as storage for documents, organized to facilitate efficient information retrieval. Manipulating repository content is straightforward.
### Document creation
To add a document to a repository, you can use the `create` method provided by the `document` API. Here's an example of how to create and upload a document:


<CodeGroup>
```python Python
FILE_CONTENT = "My friend Jack has a beautiful pet, he gave it the name Sparky, [...]"

response = client.repository.document.create(
	repository_id=REPOSITORY_ID,
	name="pets_and_their_owners.txt",
	content=FILE_CONTENT,
	document_type="text",
)

print(response)
# E.g., DocumentOutput(repository_id=4, document_id=14, name="pets_and_their_owners.txt", type="text", status="UPLOADED", chunk_count=0, error=None)
```
```javascript JavaScript
const FILE_CONTENT = "My friend Jack has a beautiful pet, he gave it the name Sparky, [...]"

const response = await client.repository.document.create(
    REPOSITORY_ID,
    {
        name: "pets_and_their_owners.txt",
        content: FILE_CONTENT,
        document_type: "text"
    }
)

console.log(response)
// E.g. {repository_id: 4, document_id: 14, name: "pets_and_their_owners.txt", type: "text", status: "UPLOADED", chunk_count: 0, error: null}
```  
</CodeGroup>



After uploading, the document state is reflected in fields such as:

-   `status`: Shows `UPLOADED` initially, changes once processed (e.g., `PROCESSING`).
-   `chunk_count`: Number of data chunks; starts at 0 and increases post-processing.
-   `error`: Non-null if an error arose during processing.
