---
title: Available Models
description: Learn about the available models in Prem.
---


# Here's a list of the available models:

| Name | Finetunable | Description |
| ---- | :---------: | ----------- |
| claude-3.5-haiku |  | Fast, efficient Anthropic model for everyday tasks. Good at concise responses and basic reasoning. |
| claude-3.5-sonnet |  | Balanced Anthropic model with strong reasoning and creative capabilities. |
| claude-3.7-sonnet |  | Powerful Anthropic model optimized for complex reasoning and precise instruction following. |
| claude-4-sonnet |  | Advanced Anthropic model with exceptional reasoning, creativity and natural language understanding. |
| claude-4.5-sonnet |  | Latest Anthropic model with state-of-the-art reasoning, creativity and natural language understanding. |
| deepseek-r1 |  | Code-specialized model with strong programming and technical reasoning capabilities. |
| deepseek-v3.1 |  | A powerful open-source model with a hybrid "think" and "non-think" mode for complex reasoning and fast responses. |
| gemma3-1b | ✅ | Compact Google model for efficient, lightweight applications. |
| gemma3-270m | ✅ | A compact and power-efficient model ideal for on-device applications and specialized, fine-tuned tasks. |
| gemma3-4b |  | Balanced Google model offering good performance for general tasks at moderate size. |
| glm-4.6 |  | An advanced coding and reasoning model with a large context window for complex development tasks. |
| gpt-5 |  | A multimodal model with state-of-the-art performance, featuring a router for selecting the best internal model for a given task. |
| gpt-5-mini |  | A compact version of GPT-5 designed for lighter-weight reasoning tasks with reduced latency and cost. |
| gpt-5-nano |  | The smallest and fastest GPT-5 variant, optimized for developer tools and real-time applications. |
| gpt-oss-120b |  | An open-weight model from OpenAI, designed for high-reasoning, agentic, and general-purpose use cases. |
| gpt-oss-20b | ✅ | A medium-sized open-weight model from OpenAI for low latency, local, or specialized use cases. |
| llama3.1-8b | ✅ | Mid-sized Meta model balancing performance and resource efficiency. |
| llama3.2-1b | ✅ | Compact Meta model for lightweight applications with minimal resource needs. |
| llama3.2-3b | ✅ | Balanced Meta model for general-purpose tasks with reasonable resource requirements. |
| llama3.3-70b-instruct |  | Large instruction-tuned Meta model with advanced reasoning capabilities. |
| nova-lite |  | Lighter version of Anthropic's Nova model for everyday tasks. |
| nova-micro |  | Most compact Nova model optimized for speed and efficiency. |
| nova-pro |  | Premium Anthropic Nova model with advanced capabilities for complex tasks. |
| phi-3.5-mini | ✅ | Microsoft's compact Phi model designed for efficient performance on smaller devices. |
| phi-4 |  | Microsoft's latest Phi model with enhanced reasoning and instruction-following capabilities. |
| phi-4-mini | ✅ | Smaller version of Phi-4 optimized for speed and efficiency while maintaining strong performance. |
| qwen-flash |  | A fast and cost-effective model for real-time translation and other language tasks. |
| qwen2.5-0.5b | ✅ | Ultra-compact Alibaba model for extremely lightweight applications. |
| qwen2.5-1.5b | ✅ | Compact Alibaba model balancing efficiency and basic capabilities. |
| qwen2.5-3b | ✅ | Mid-sized Alibaba model with good performance for everyday tasks. |
| qwen2.5-7b | ✅ | Larger Alibaba model with enhanced reasoning and generation capabilities. |
| qwen2.5-math-1.5b | ✅ | Specialized Alibaba model optimized for mathematical reasoning and problem-solving. |
| qwen2.5-math-7b | ✅ | Advanced mathematical reasoning model with enhanced capabilities for complex calculations. |
| qwen3-max |  | Alibaba's largest and most capable model, with advanced reasoning and multilingual support. |
| smollm-1.7b | ✅ | Efficient small model optimized for resource-constrained environments. |
| smollm-135m | ✅ | Tiny model for basic tasks with minimal computational requirements. |
| smollm-360m | ✅ | Very small model balancing capability and extreme efficiency. |
