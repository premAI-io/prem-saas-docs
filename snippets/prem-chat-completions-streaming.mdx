<CodeGroup>
```javascript javascript/typescript
import PremAI from "premai";

const client = new PremAI({
    apiKey: process.env.PREMAI_API_KEY,
});

// Create a chat completion
const response = await client.chat.completions.create({
    kidmodel: "llama3.2-3b", //Or any other model you want to use
    messages: [{ role: "user", content: "Write a one-sentence bedtime story about a unicorn." }],
    stream: true,
});

for await (const chunk of response) {
    process.stdout.write(chunk.choices[0].delta.content);
}
```
```python python
import os
from premai import PremAI

client = PremAI(
    api_key=os.environ.get("PREMAI_API_KEY"),
)

# Create completion
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Who won the world series in 2020?"}],
    model="llama3.2-3b", # Or any other model you want to use
    stream=True,
)

for chunk in response:
    print(chunk.choices[0].delta.content, end='', flush=True)
```
```python python (async)
import os
from openai import AsyncPremAI

client = AsyncPremAI(
    api_key=os.environ.get("PREMAI_API_KEY"),
)

# Create completion
response = await client.chat.completions.create(
    messages=[{"role": "user", "content": "Who won the world series in 2020?"}],
    model="llama3.2-3b", # Or any other model you want to use
    stream=True,
)

async for chunk in response:
    print(chunk.choices[0].delta.content, end='', flush=True)
```
</CodeGroup>
